{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mo7g_vyIrp9B"},"outputs":[],"source":["# If load_boston does not work then download the data and use this.\n","# Data : https://github.com/afnan47/sem8/blob/master/DL/1_boston_housing.csv\n","import pandas as pd\n","df = pd.read_csv(\"/content/1_boston_housing.csv\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"4FEDjg8rsyi0","executionInfo":{"status":"ok","timestamp":1745783461625,"user_tz":-330,"elapsed":63,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","# Separating features (X) and target variable (y)\n","X = df.loc[:, df.columns != 'MEDV']# All columns except 'MEDV' as features\n","y = df.loc[:, df.columns == 'MEDV']# Only 'MEDV' as the target (house price)\n","# Splitting data into 70% training and 30% testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ynsPtHurp9C"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","# Initializing MinMaxScaler to scale feature values between 0 and 1\n","mms = MinMaxScaler()\n","# Fitting the scaler only on training data\n","mms.fit(X_train)\n","# Transforming both training and testing feature sets based on fitted scaler\n","X_train = mms.transform(X_train)\n","X_test = mms.transform(X_test)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"VL8VMy_fs3fl","outputId":"c5c3978a-d1fd-46e2-a3e5-06edf983397d","executionInfo":{"status":"ok","timestamp":1745783651270,"user_tz":-330,"elapsed":185,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","# Building the Deep Neural Network model\n","model = Sequential()\n","# Adding the first hidden layer\n","model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n","# Adding the second hidden layer\n","model.add(Dense(64, activation='relu', name='dense_2'))\n","# Adding the output layer (single neuron because we're predicting one value)\n","model.add(Dense(1, activation='linear', name='dense_output'))\n","# Compiling the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# Showing the model summary (number of layers, parameters, etc.)\n","model.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7m71ooKs5of","outputId":"df263f43-0dbf-49f9-d993-52e8816c08fd","executionInfo":{"status":"ok","timestamp":1745783686169,"user_tz":-330,"elapsed":17420,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 1853.9795 - mae: 36.2284 - val_loss: 187.6848 - val_mae: 12.6001\n","Epoch 2/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 185.2761 - mae: 11.3351 - val_loss: 145.9320 - val_mae: 8.2227\n","Epoch 3/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 107.7885 - mae: 8.0496 - val_loss: 137.5693 - val_mae: 10.4022\n","Epoch 4/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 84.3720 - mae: 7.1580 - val_loss: 113.5810 - val_mae: 6.9078\n","Epoch 5/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 77.2716 - mae: 6.1493 - val_loss: 105.1562 - val_mae: 8.0251\n","Epoch 6/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 66.1888 - mae: 5.6504 - val_loss: 100.9622 - val_mae: 7.4376\n","Epoch 7/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 58.2336 - mae: 5.5333 - val_loss: 100.0464 - val_mae: 7.4345\n","Epoch 8/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 57.4302 - mae: 5.2459 - val_loss: 98.5448 - val_mae: 7.4644\n","Epoch 9/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 49.9721 - mae: 5.1478 - val_loss: 98.0880 - val_mae: 7.2257\n","Epoch 10/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 65.1401 - mae: 5.5295 - val_loss: 95.8851 - val_mae: 7.1694\n","Epoch 11/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 58.4769 - mae: 5.3502 - val_loss: 94.7500 - val_mae: 7.4133\n","Epoch 12/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 52.0814 - mae: 5.1743 - val_loss: 93.6365 - val_mae: 6.7144\n","Epoch 13/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 48.5371 - mae: 4.9838 - val_loss: 91.8339 - val_mae: 7.4304\n","Epoch 14/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 54.7855 - mae: 5.3658 - val_loss: 90.6779 - val_mae: 6.3279\n","Epoch 15/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 46.6436 - mae: 4.7102 - val_loss: 89.1670 - val_mae: 7.2667\n","Epoch 16/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 47.7943 - mae: 5.1060 - val_loss: 87.1512 - val_mae: 6.8006\n","Epoch 17/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 48.9777 - mae: 5.1641 - val_loss: 86.0923 - val_mae: 6.3472\n","Epoch 18/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 48.2630 - mae: 4.7302 - val_loss: 84.2357 - val_mae: 6.5713\n","Epoch 19/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 47.0203 - mae: 4.9865 - val_loss: 81.8292 - val_mae: 6.3115\n","Epoch 20/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 56.5739 - mae: 5.3790 - val_loss: 81.1963 - val_mae: 6.2887\n","Epoch 21/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 49.8627 - mae: 4.9262 - val_loss: 82.6266 - val_mae: 5.9862\n","Epoch 22/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 58.9273 - mae: 5.1072 - val_loss: 82.0404 - val_mae: 5.8795\n","Epoch 23/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 36.8173 - mae: 4.3707 - val_loss: 79.2363 - val_mae: 6.8183\n","Epoch 24/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 39.9715 - mae: 4.6443 - val_loss: 89.1198 - val_mae: 7.8795\n","Epoch 25/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 60.1119 - mae: 6.0531 - val_loss: 78.3704 - val_mae: 5.8734\n","Epoch 26/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 45.9063 - mae: 4.8966 - val_loss: 87.3313 - val_mae: 5.6948\n","Epoch 27/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 50.6703 - mae: 5.0094 - val_loss: 78.1566 - val_mae: 5.4455\n","Epoch 28/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 46.6932 - mae: 4.6303 - val_loss: 69.8159 - val_mae: 6.1087\n","Epoch 29/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.6104 - mae: 4.5885 - val_loss: 70.6692 - val_mae: 6.0722\n","Epoch 30/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 47.1641 - mae: 4.5887 - val_loss: 68.2757 - val_mae: 6.1691\n","Epoch 31/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 39.1197 - mae: 4.2957 - val_loss: 67.4540 - val_mae: 5.8152\n","Epoch 32/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.9645 - mae: 4.2263 - val_loss: 65.7029 - val_mae: 6.0085\n","Epoch 33/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43.2498 - mae: 4.8869 - val_loss: 66.0473 - val_mae: 5.9110\n","Epoch 34/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.6168 - mae: 4.7707 - val_loss: 72.2797 - val_mae: 5.6029\n","Epoch 35/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44.4803 - mae: 4.4519 - val_loss: 66.2660 - val_mae: 5.7316\n","Epoch 36/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 48.5362 - mae: 4.9164 - val_loss: 72.5816 - val_mae: 5.6975\n","Epoch 37/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.8317 - mae: 3.9357 - val_loss: 63.8292 - val_mae: 6.0948\n","Epoch 38/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.9677 - mae: 4.1869 - val_loss: 62.6730 - val_mae: 6.2722\n","Epoch 39/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 38.4133 - mae: 4.5649 - val_loss: 65.4793 - val_mae: 5.7522\n","Epoch 40/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.8070 - mae: 4.1729 - val_loss: 64.1342 - val_mae: 5.7493\n","Epoch 41/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 35.8149 - mae: 4.2957 - val_loss: 68.2271 - val_mae: 5.8735\n","Epoch 42/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45.5435 - mae: 4.6844 - val_loss: 68.4389 - val_mae: 5.8922\n","Epoch 43/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.3105 - mae: 4.0843 - val_loss: 76.0029 - val_mae: 5.9460\n","Epoch 44/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.7260 - mae: 4.3632 - val_loss: 63.6776 - val_mae: 5.9025\n","Epoch 45/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.1723 - mae: 4.0363 - val_loss: 67.6927 - val_mae: 5.8273\n","Epoch 46/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.3780 - mae: 4.3951 - val_loss: 82.8584 - val_mae: 6.0771\n","Epoch 47/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.1818 - mae: 3.9031 - val_loss: 64.1153 - val_mae: 5.9975\n","Epoch 48/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 30.2108 - mae: 3.9959 - val_loss: 70.7047 - val_mae: 5.7651\n","Epoch 49/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.4348 - mae: 4.0313 - val_loss: 82.0036 - val_mae: 6.0757\n","Epoch 50/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.7868 - mae: 4.0306 - val_loss: 71.9750 - val_mae: 5.8533\n","Epoch 51/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35.1935 - mae: 4.1320 - val_loss: 63.1936 - val_mae: 6.4112\n","Epoch 52/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.5057 - mae: 4.3244 - val_loss: 64.0475 - val_mae: 6.8175\n","Epoch 53/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.4009 - mae: 4.2710 - val_loss: 66.9056 - val_mae: 5.8721\n","Epoch 54/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.4163 - mae: 4.1782 - val_loss: 86.4913 - val_mae: 6.1010\n","Epoch 55/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.7585 - mae: 4.1900 - val_loss: 86.0452 - val_mae: 6.2504\n","Epoch 56/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31.6213 - mae: 4.1638 - val_loss: 80.1148 - val_mae: 6.0632\n","Epoch 57/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.1500 - mae: 3.9022 - val_loss: 70.4924 - val_mae: 6.0716\n","Epoch 58/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 33.4877 - mae: 4.3925 - val_loss: 63.2452 - val_mae: 6.6719\n","Epoch 59/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 30.2004 - mae: 4.1098 - val_loss: 66.4323 - val_mae: 6.4155\n","Epoch 60/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 30.2227 - mae: 4.0255 - val_loss: 74.0379 - val_mae: 5.9472\n","Epoch 61/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.4977 - mae: 3.9299 - val_loss: 84.4888 - val_mae: 6.0880\n","Epoch 62/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30.9841 - mae: 4.0066 - val_loss: 82.0982 - val_mae: 6.0915\n","Epoch 63/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25.1419 - mae: 3.6894 - val_loss: 85.9229 - val_mae: 6.0898\n","Epoch 64/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.0814 - mae: 3.7596 - val_loss: 75.8676 - val_mae: 6.0640\n","Epoch 65/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24.1965 - mae: 3.6358 - val_loss: 76.5547 - val_mae: 5.9948\n","Epoch 66/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 26.1654 - mae: 3.6906 - val_loss: 77.4940 - val_mae: 6.5839\n","Epoch 67/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 35.1540 - mae: 4.4906 - val_loss: 76.7099 - val_mae: 6.0354\n","Epoch 68/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.2007 - mae: 3.8449 - val_loss: 91.9916 - val_mae: 6.3439\n","Epoch 69/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 30.6262 - mae: 4.2004 - val_loss: 75.1729 - val_mae: 6.2286\n","Epoch 70/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 28.2764 - mae: 4.0257 - val_loss: 68.7364 - val_mae: 6.5160\n","Epoch 71/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 28.3210 - mae: 3.9931 - val_loss: 81.8678 - val_mae: 5.9592\n","Epoch 72/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.1972 - mae: 3.5093 - val_loss: 76.9282 - val_mae: 6.0880\n","Epoch 73/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24.6786 - mae: 3.6386 - val_loss: 75.7867 - val_mae: 5.9001\n","Epoch 74/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 27.3419 - mae: 3.8262 - val_loss: 79.7774 - val_mae: 6.0064\n","Epoch 75/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20.7056 - mae: 3.4179 - val_loss: 71.7779 - val_mae: 6.6674\n","Epoch 76/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 26.7601 - mae: 3.9183 - val_loss: 81.3587 - val_mae: 5.8676\n","Epoch 77/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 29.2095 - mae: 4.0438 - val_loss: 124.1733 - val_mae: 8.1483\n","Epoch 78/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39.6580 - mae: 4.6221 - val_loss: 79.2258 - val_mae: 5.8556\n","Epoch 79/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.2268 - mae: 4.2650 - val_loss: 64.7931 - val_mae: 6.5853\n","Epoch 80/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.5370 - mae: 4.0729 - val_loss: 70.9820 - val_mae: 5.9119\n","Epoch 81/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27.2800 - mae: 3.8141 - val_loss: 73.6006 - val_mae: 5.9252\n","Epoch 82/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 22.7164 - mae: 3.5625 - val_loss: 71.4592 - val_mae: 5.8647\n","Epoch 83/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.0545 - mae: 3.7545 - val_loss: 68.6273 - val_mae: 5.7557\n","Epoch 84/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19.1434 - mae: 3.3402 - val_loss: 66.4101 - val_mae: 5.7824\n","Epoch 85/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.3149 - mae: 3.5638 - val_loss: 74.5515 - val_mae: 5.4778\n","Epoch 86/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.9987 - mae: 3.6468 - val_loss: 69.6229 - val_mae: 5.6819\n","Epoch 87/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22.1007 - mae: 3.5274 - val_loss: 78.7049 - val_mae: 5.7360\n","Epoch 88/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.8149 - mae: 3.7901 - val_loss: 69.9093 - val_mae: 5.3632\n","Epoch 89/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29.2526 - mae: 4.1206 - val_loss: 69.1135 - val_mae: 5.3579\n","Epoch 90/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22.0780 - mae: 3.5172 - val_loss: 62.1602 - val_mae: 5.4077\n","Epoch 91/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.2551 - mae: 3.5611 - val_loss: 62.9564 - val_mae: 5.6991\n","Epoch 92/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.1433 - mae: 3.8935 - val_loss: 109.1747 - val_mae: 7.6678\n","Epoch 93/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 32.8930 - mae: 4.2340 - val_loss: 73.5948 - val_mae: 5.4489\n","Epoch 94/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.7423 - mae: 4.0225 - val_loss: 60.1089 - val_mae: 5.7322\n","Epoch 95/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24.1914 - mae: 3.7439 - val_loss: 62.6310 - val_mae: 5.2851\n","Epoch 96/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.8223 - mae: 3.4194 - val_loss: 85.3207 - val_mae: 6.4654\n","Epoch 97/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.5605 - mae: 4.3718 - val_loss: 66.7306 - val_mae: 5.2104\n","Epoch 98/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 26.4684 - mae: 4.0560 - val_loss: 60.8070 - val_mae: 5.4665\n","Epoch 99/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 22.8309 - mae: 3.4477 - val_loss: 57.6538 - val_mae: 6.0050\n","Epoch 100/100\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22.7366 - mae: 3.7046 - val_loss: 63.4900 - val_mae: 5.2812\n"]}],"source":["# Training the model on training data\n","history = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose = 1)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzY8zjL5s9jS","outputId":"cbd9057e-1f8d-4133-9696-e3572cb01382","executionInfo":{"status":"ok","timestamp":1745783697452,"user_tz":-330,"elapsed":152,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.3563 - mae: 3.9836 \n","Mean squared error on test data:  25.33142852783203\n","Mean absolute error on test data:  3.7423248291015625\n"]}],"source":["# Evaluating the model performance on test data\n","mse_nn, mae_nn = model.evaluate(X_test, y_test)\n","# Printing the results\n","print('Mean squared error on test data: ', mse_nn)\n","print('Mean absolute error on test data: ', mae_nn)"]},{"cell_type":"code","source":["print(X.columns.tolist())\n","#printing features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZuY3NQMuMaB","executionInfo":{"status":"ok","timestamp":1745782101053,"user_tz":-330,"elapsed":44,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}},"outputId":"6881f1ba-055f-4716-bceb-fa44b0db13ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n"]}]},{"cell_type":"code","source":["\n","import numpy as np  # Importing numpy for numerical arrays\n","\n","# Creating a new sample input (example values for the 13 features)\n","new_data = np.array([[0.1, 18.0, 2.31, 0, 0.538, 6.575, 65.2, 4.09, 1, 296, 15.3, 396.9, 4.98]])\n","\n","# Scaling the new input data using the same scaler fitted earlier\n","new_data_scaled = mms.transform(new_data)\n","\n","# Predicting house price using the trained neural network\n","prediction = model.predict(new_data_scaled)\n","\n","# Printing the predicted house price\n","print(\"\\nPredicted House Price:\", prediction[0][0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9Nr-BpQwxc6","executionInfo":{"status":"ok","timestamp":1745783742018,"user_tz":-330,"elapsed":175,"user":{"displayName":"PRATHMESH BHISE","userId":"10624294756255944730"}},"outputId":"603ce94f-ad13-4b4c-dee3-f8aa1123a24c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n","\n","Predicted House Price: 0.5275891\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n","  warnings.warn(\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}